Loading train.pt and valid.pt from data/processed_100k
Train samples: 99392, Valid samples: 486
Parameters: 44,797,712
Training transformer on cuda
/data/250010067/courses/NLP/NLP_midterm_project/train.py:100: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with autocast(enabled=self.use_amp):
Epoch 0 | Batch 0/1553 | Loss: 9.2797
Epoch 0 | Batch 100/1553 | Loss: 8.1960
Epoch 0 | Batch 200/1553 | Loss: 7.1859
Epoch 0 | Batch 300/1553 | Loss: 6.3705
Epoch 0 | Batch 400/1553 | Loss: 6.0944
Epoch 0 | Batch 500/1553 | Loss: 5.8591
Epoch 0 | Batch 600/1553 | Loss: 5.6820
Epoch 0 | Batch 700/1553 | Loss: 5.5661
Epoch 0 | Batch 800/1553 | Loss: 5.4518
Epoch 0 | Batch 900/1553 | Loss: 5.4256
Epoch 0 | Batch 1000/1553 | Loss: 5.2494
Epoch 0 | Batch 1100/1553 | Loss: 5.0690
Epoch 0 | Batch 1200/1553 | Loss: 4.8514
Epoch 0 | Batch 1300/1553 | Loss: 4.8745
Epoch 0 | Batch 1400/1553 | Loss: 4.7384
Epoch 0 | Batch 1500/1553 | Loss: 4.6728
/data/250010067/courses/NLP/NLP_midterm_project/train.py:141: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with autocast(enabled=self.use_amp):
Epoch 0 | Time: 35.6s | Train Loss: 5.8058 | Val Loss: 4.9485
New best model! Val Loss: 4.9485
Epoch 1 | Batch 0/1553 | Loss: 4.6222
Epoch 1 | Batch 100/1553 | Loss: 4.5202
Epoch 1 | Batch 200/1553 | Loss: 4.4553
Epoch 1 | Batch 300/1553 | Loss: 4.2506
Epoch 1 | Batch 400/1553 | Loss: 4.3972
Epoch 1 | Batch 500/1553 | Loss: 4.2473
Epoch 1 | Batch 600/1553 | Loss: 4.1849
Epoch 1 | Batch 700/1553 | Loss: 4.1549
Epoch 1 | Batch 800/1553 | Loss: 4.0327
Epoch 1 | Batch 900/1553 | Loss: 3.9894
Epoch 1 | Batch 1000/1553 | Loss: 3.9409
Epoch 1 | Batch 1100/1553 | Loss: 3.8382
Epoch 1 | Batch 1200/1553 | Loss: 3.7517
Epoch 1 | Batch 1300/1553 | Loss: 3.8155
Epoch 1 | Batch 1400/1553 | Loss: 3.6264
Epoch 1 | Batch 1500/1553 | Loss: 3.5699
Epoch 1 | Time: 35.4s | Train Loss: 4.0306 | Val Loss: 4.1858
New best model! Val Loss: 4.1858
Epoch 2 | Batch 0/1553 | Loss: 3.2993
Epoch 2 | Batch 100/1553 | Loss: 3.3988
Epoch 2 | Batch 200/1553 | Loss: 3.3858
Epoch 2 | Batch 300/1553 | Loss: 3.5693
Epoch 2 | Batch 400/1553 | Loss: 3.2136
Epoch 2 | Batch 500/1553 | Loss: 3.3180
Epoch 2 | Batch 600/1553 | Loss: 3.2928
Epoch 2 | Batch 700/1553 | Loss: 3.2373
Epoch 2 | Batch 800/1553 | Loss: 3.2349
Epoch 2 | Batch 900/1553 | Loss: 3.3505
Epoch 2 | Batch 1000/1553 | Loss: 3.2789
Epoch 2 | Batch 1100/1553 | Loss: 3.0332
Epoch 2 | Batch 1200/1553 | Loss: 3.2859
Epoch 2 | Batch 1300/1553 | Loss: 2.9975
Epoch 2 | Batch 1400/1553 | Loss: 2.9667
Epoch 2 | Batch 1500/1553 | Loss: 3.0794
Epoch 2 | Time: 35.0s | Train Loss: 3.2309 | Val Loss: 3.8493
New best model! Val Loss: 3.8493
Epoch 3 | Batch 0/1553 | Loss: 2.6766
Epoch 3 | Batch 100/1553 | Loss: 2.8321
Epoch 3 | Batch 200/1553 | Loss: 2.6860
Epoch 3 | Batch 300/1553 | Loss: 2.7085
Epoch 3 | Batch 400/1553 | Loss: 2.8087
Epoch 3 | Batch 500/1553 | Loss: 2.7863
Epoch 3 | Batch 600/1553 | Loss: 2.7947
Epoch 3 | Batch 700/1553 | Loss: 2.8857
Epoch 3 | Batch 800/1553 | Loss: 2.5850
Epoch 3 | Batch 900/1553 | Loss: 2.6934
Epoch 3 | Batch 1000/1553 | Loss: 2.6949
Epoch 3 | Batch 1100/1553 | Loss: 2.8842
Epoch 3 | Batch 1200/1553 | Loss: 2.6576
Epoch 3 | Batch 1300/1553 | Loss: 2.6918
Epoch 3 | Batch 1400/1553 | Loss: 2.6931
Epoch 3 | Batch 1500/1553 | Loss: 2.3979
Epoch 3 | Time: 35.1s | Train Loss: 2.7346 | Val Loss: 3.6378
New best model! Val Loss: 3.6378
Epoch 4 | Batch 0/1553 | Loss: 2.4445
Epoch 4 | Batch 100/1553 | Loss: 2.4209
Epoch 4 | Batch 200/1553 | Loss: 2.4440
Epoch 4 | Batch 300/1553 | Loss: 2.5162
Epoch 4 | Batch 400/1553 | Loss: 2.5147
Epoch 4 | Batch 500/1553 | Loss: 2.3214
Epoch 4 | Batch 600/1553 | Loss: 2.6622
Epoch 4 | Batch 700/1553 | Loss: 2.3703
Epoch 4 | Batch 800/1553 | Loss: 2.5356
Epoch 4 | Batch 900/1553 | Loss: 2.3932
Epoch 4 | Batch 1000/1553 | Loss: 2.5975
Epoch 4 | Batch 1100/1553 | Loss: 2.3439
Epoch 4 | Batch 1200/1553 | Loss: 2.4458
Epoch 4 | Batch 1300/1553 | Loss: 2.3613
Epoch 4 | Batch 1400/1553 | Loss: 2.5656
Epoch 4 | Batch 1500/1553 | Loss: 2.4313
Epoch 4 | Time: 35.5s | Train Loss: 2.4006 | Val Loss: 3.6036
New best model! Val Loss: 3.6036
Epoch 5 | Batch 0/1553 | Loss: 2.2044
Epoch 5 | Batch 100/1553 | Loss: 2.0982
Epoch 5 | Batch 200/1553 | Loss: 2.1248
Epoch 5 | Batch 300/1553 | Loss: 2.0472
Epoch 5 | Batch 400/1553 | Loss: 2.1899
Epoch 5 | Batch 500/1553 | Loss: 2.0816
Epoch 5 | Batch 600/1553 | Loss: 2.0493
Epoch 5 | Batch 700/1553 | Loss: 2.1577
Epoch 5 | Batch 800/1553 | Loss: 1.9785
Epoch 5 | Batch 900/1553 | Loss: 2.2112
Epoch 5 | Batch 1000/1553 | Loss: 2.2667
Epoch 5 | Batch 1100/1553 | Loss: 2.0319
Epoch 5 | Batch 1200/1553 | Loss: 2.1361
Epoch 5 | Batch 1300/1553 | Loss: 2.2536
Epoch 5 | Batch 1400/1553 | Loss: 2.1864
Epoch 5 | Batch 1500/1553 | Loss: 2.2015
Epoch 5 | Time: 35.2s | Train Loss: 2.1612 | Val Loss: 3.5760
New best model! Val Loss: 3.5760
Epoch 6 | Batch 0/1553 | Loss: 1.9734
Epoch 6 | Batch 100/1553 | Loss: 1.7938
Epoch 6 | Batch 200/1553 | Loss: 1.8927
Epoch 6 | Batch 300/1553 | Loss: 2.0516
Epoch 6 | Batch 400/1553 | Loss: 1.8632
Epoch 6 | Batch 500/1553 | Loss: 2.0079
Epoch 6 | Batch 600/1553 | Loss: 1.9446
Epoch 6 | Batch 700/1553 | Loss: 1.8161
Epoch 6 | Batch 800/1553 | Loss: 2.0141
Epoch 6 | Batch 900/1553 | Loss: 1.9809
Epoch 6 | Batch 1000/1553 | Loss: 2.1248
Epoch 6 | Batch 1100/1553 | Loss: 1.9761
Epoch 6 | Batch 1200/1553 | Loss: 2.0892
Epoch 6 | Batch 1300/1553 | Loss: 1.9440
Epoch 6 | Batch 1400/1553 | Loss: 2.0884
Epoch 6 | Batch 1500/1553 | Loss: 2.1473
Epoch 6 | Time: 35.3s | Train Loss: 1.9729 | Val Loss: 3.5601
New best model! Val Loss: 3.5601
Epoch 7 | Batch 0/1553 | Loss: 1.7750
Epoch 7 | Batch 100/1553 | Loss: 1.8189
Epoch 7 | Batch 200/1553 | Loss: 1.7907
Epoch 7 | Batch 300/1553 | Loss: 1.8563
Epoch 7 | Batch 400/1553 | Loss: 1.6644
Epoch 7 | Batch 500/1553 | Loss: 1.7584
Epoch 7 | Batch 600/1553 | Loss: 1.8780
Epoch 7 | Batch 700/1553 | Loss: 1.8013
Epoch 7 | Batch 800/1553 | Loss: 1.8009
Epoch 7 | Batch 900/1553 | Loss: 1.7804
Epoch 7 | Batch 1000/1553 | Loss: 1.9240
Epoch 7 | Batch 1100/1553 | Loss: 1.7910
Epoch 7 | Batch 1200/1553 | Loss: 2.0223
Epoch 7 | Batch 1300/1553 | Loss: 1.8198
Epoch 7 | Batch 1400/1553 | Loss: 1.9554
Epoch 7 | Batch 1500/1553 | Loss: 1.8182
Epoch 7 | Time: 35.3s | Train Loss: 1.8132 | Val Loss: 3.6019
Epoch 8 | Batch 0/1553 | Loss: 1.6473
Epoch 8 | Batch 100/1553 | Loss: 1.4132
Epoch 8 | Batch 200/1553 | Loss: 1.6115
Epoch 8 | Batch 300/1553 | Loss: 1.6246
Epoch 8 | Batch 400/1553 | Loss: 1.6150
Epoch 8 | Batch 500/1553 | Loss: 1.5797
Epoch 8 | Batch 600/1553 | Loss: 1.6341
Epoch 8 | Batch 700/1553 | Loss: 1.5440
Epoch 8 | Batch 800/1553 | Loss: 1.5618
Epoch 8 | Batch 900/1553 | Loss: 1.6588
Epoch 8 | Batch 1000/1553 | Loss: 1.7875
Epoch 8 | Batch 1100/1553 | Loss: 1.6979
Epoch 8 | Batch 1200/1553 | Loss: 1.7354
Epoch 8 | Batch 1300/1553 | Loss: 1.6902
Epoch 8 | Batch 1400/1553 | Loss: 1.7756
Epoch 8 | Batch 1500/1553 | Loss: 1.6195
Epoch 8 | Time: 35.5s | Train Loss: 1.6766 | Val Loss: 3.6492
Epoch 9 | Batch 0/1553 | Loss: 1.4112
Epoch 9 | Batch 100/1553 | Loss: 1.4445
Epoch 9 | Batch 200/1553 | Loss: 1.5192
Epoch 9 | Batch 300/1553 | Loss: 1.4830
Epoch 9 | Batch 400/1553 | Loss: 1.5025
Epoch 9 | Batch 500/1553 | Loss: 1.4878
Epoch 9 | Batch 600/1553 | Loss: 1.5715
Epoch 9 | Batch 700/1553 | Loss: 1.4256
Epoch 9 | Batch 800/1553 | Loss: 1.4770
Epoch 9 | Batch 900/1553 | Loss: 1.6665
Epoch 9 | Batch 1000/1553 | Loss: 1.6590
Epoch 9 | Batch 1100/1553 | Loss: 1.7103
Epoch 9 | Batch 1200/1553 | Loss: 1.4825
Epoch 9 | Batch 1300/1553 | Loss: 1.5382
Epoch 9 | Batch 1400/1553 | Loss: 1.5667
Epoch 9 | Batch 1500/1553 | Loss: 1.5862
Epoch 9 | Time: 35.6s | Train Loss: 1.5555 | Val Loss: 3.7324
Epoch 10 | Batch 0/1553 | Loss: 1.2277
Epoch 10 | Batch 100/1553 | Loss: 1.4889
Epoch 10 | Batch 200/1553 | Loss: 1.4379
Epoch 10 | Batch 300/1553 | Loss: 1.4126
Epoch 10 | Batch 400/1553 | Loss: 1.3459
Epoch 10 | Batch 500/1553 | Loss: 1.3298
Epoch 10 | Batch 600/1553 | Loss: 1.5053
Epoch 10 | Batch 700/1553 | Loss: 1.3735
Epoch 10 | Batch 800/1553 | Loss: 1.5355
Epoch 10 | Batch 900/1553 | Loss: 1.5303
Epoch 10 | Batch 1000/1553 | Loss: 1.4930
Epoch 10 | Batch 1100/1553 | Loss: 1.6472
Epoch 10 | Batch 1200/1553 | Loss: 1.5840
Epoch 10 | Batch 1300/1553 | Loss: 1.5206
Epoch 10 | Batch 1400/1553 | Loss: 1.5215
Epoch 10 | Batch 1500/1553 | Loss: 1.4898
Epoch 10 | Time: 35.6s | Train Loss: 1.4477 | Val Loss: 3.8134
Epoch 11 | Batch 0/1553 | Loss: 1.2703
Epoch 11 | Batch 100/1553 | Loss: 1.3657
Epoch 11 | Batch 200/1553 | Loss: 1.2858
Epoch 11 | Batch 300/1553 | Loss: 1.2889
Epoch 11 | Batch 400/1553 | Loss: 1.2835
Epoch 11 | Batch 500/1553 | Loss: 1.4245
Epoch 11 | Batch 600/1553 | Loss: 1.4305
Epoch 11 | Batch 700/1553 | Loss: 1.4190
Epoch 11 | Batch 800/1553 | Loss: 1.3414
Epoch 11 | Batch 900/1553 | Loss: 1.3980
Epoch 11 | Batch 1000/1553 | Loss: 1.3913
Epoch 11 | Batch 1100/1553 | Loss: 1.4044
Epoch 11 | Batch 1200/1553 | Loss: 1.4297
Epoch 11 | Batch 1300/1553 | Loss: 1.5124
Epoch 11 | Batch 1400/1553 | Loss: 1.3596
Epoch 11 | Batch 1500/1553 | Loss: 1.3794
Epoch 11 | Time: 35.1s | Train Loss: 1.3492 | Val Loss: 3.8805
Epoch 12 | Batch 0/1553 | Loss: 1.2330
Epoch 12 | Batch 100/1553 | Loss: 1.2408
Epoch 12 | Batch 200/1553 | Loss: 1.2779
Epoch 12 | Batch 300/1553 | Loss: 1.2182
Epoch 12 | Batch 400/1553 | Loss: 1.2559
Epoch 12 | Batch 500/1553 | Loss: 1.1975
Epoch 12 | Batch 600/1553 | Loss: 1.1809
Epoch 12 | Batch 700/1553 | Loss: 1.2953
Epoch 12 | Batch 800/1553 | Loss: 1.3063
Epoch 12 | Batch 900/1553 | Loss: 1.2825
Epoch 12 | Batch 1000/1553 | Loss: 1.2988
Epoch 12 | Batch 1100/1553 | Loss: 1.2848
Epoch 12 | Batch 1200/1553 | Loss: 1.3956
Epoch 12 | Batch 1300/1553 | Loss: 1.2531
Epoch 12 | Batch 1400/1553 | Loss: 1.3383
Epoch 12 | Batch 1500/1553 | Loss: 1.3470
Epoch 12 | Time: 35.0s | Train Loss: 1.2620 | Val Loss: 3.9747
Epoch 13 | Batch 0/1553 | Loss: 1.1144
Epoch 13 | Batch 100/1553 | Loss: 1.1026
Epoch 13 | Batch 200/1553 | Loss: 1.1477
Epoch 13 | Batch 300/1553 | Loss: 1.1898
Epoch 13 | Batch 400/1553 | Loss: 1.1564
Epoch 13 | Batch 500/1553 | Loss: 1.0967
Epoch 13 | Batch 600/1553 | Loss: 1.1766
Epoch 13 | Batch 700/1553 | Loss: 1.1929
Epoch 13 | Batch 800/1553 | Loss: 1.1979
Epoch 13 | Batch 900/1553 | Loss: 1.2018
Epoch 13 | Batch 1000/1553 | Loss: 1.2121
Epoch 13 | Batch 1100/1553 | Loss: 1.2713
Epoch 13 | Batch 1200/1553 | Loss: 1.1855
Epoch 13 | Batch 1300/1553 | Loss: 1.1777
Epoch 13 | Batch 1400/1553 | Loss: 1.2191
Epoch 13 | Batch 1500/1553 | Loss: 1.2900
Epoch 13 | Time: 35.2s | Train Loss: 1.1822 | Val Loss: 4.0442
Epoch 14 | Batch 0/1553 | Loss: 1.0259
Epoch 14 | Batch 100/1553 | Loss: 1.0200
Epoch 14 | Batch 200/1553 | Loss: 1.0672
Epoch 14 | Batch 300/1553 | Loss: 1.0316
Epoch 14 | Batch 400/1553 | Loss: 1.0477
Epoch 14 | Batch 500/1553 | Loss: 1.0818
Epoch 14 | Batch 600/1553 | Loss: 1.0914
Epoch 14 | Batch 700/1553 | Loss: 1.0984
Epoch 14 | Batch 800/1553 | Loss: 1.0918
Epoch 14 | Batch 900/1553 | Loss: 1.0671
Epoch 14 | Batch 1000/1553 | Loss: 1.1325
Epoch 14 | Batch 1100/1553 | Loss: 1.1497
Epoch 14 | Batch 1200/1553 | Loss: 1.1221
Epoch 14 | Batch 1300/1553 | Loss: 1.2274
Epoch 14 | Batch 1400/1553 | Loss: 1.0058
Epoch 14 | Batch 1500/1553 | Loss: 1.1978
Epoch 14 | Time: 35.8s | Train Loss: 1.1096 | Val Loss: 4.1027
Epoch 15 | Batch 0/1553 | Loss: 0.9055
Epoch 15 | Batch 100/1553 | Loss: 0.9608
Epoch 15 | Batch 200/1553 | Loss: 1.0075
Epoch 15 | Batch 300/1553 | Loss: 0.9745
Epoch 15 | Batch 400/1553 | Loss: 0.9696
Epoch 15 | Batch 500/1553 | Loss: 1.0638
Epoch 15 | Batch 600/1553 | Loss: 1.0120
Epoch 15 | Batch 700/1553 | Loss: 1.0616
Epoch 15 | Batch 800/1553 | Loss: 0.9875
Epoch 15 | Batch 900/1553 | Loss: 0.9901
Epoch 15 | Batch 1000/1553 | Loss: 1.1401
Epoch 15 | Batch 1100/1553 | Loss: 1.1788
Epoch 15 | Batch 1200/1553 | Loss: 1.1088
Epoch 15 | Batch 1300/1553 | Loss: 1.1209
Epoch 15 | Batch 1400/1553 | Loss: 1.1331
Epoch 15 | Batch 1500/1553 | Loss: 1.0993
Epoch 15 | Time: 35.3s | Train Loss: 1.0437 | Val Loss: 4.1990
Epoch 16 | Batch 0/1553 | Loss: 0.8231
Epoch 16 | Batch 100/1553 | Loss: 0.8314
Epoch 16 | Batch 200/1553 | Loss: 0.9940
Epoch 16 | Batch 300/1553 | Loss: 0.8970
Epoch 16 | Batch 400/1553 | Loss: 0.9898
Epoch 16 | Batch 500/1553 | Loss: 0.9510
Epoch 16 | Batch 600/1553 | Loss: 0.9977
Epoch 16 | Batch 700/1553 | Loss: 0.9824
Epoch 16 | Batch 800/1553 | Loss: 0.9950
Epoch 16 | Batch 900/1553 | Loss: 1.0704
Epoch 16 | Batch 1000/1553 | Loss: 0.9969
Epoch 16 | Batch 1100/1553 | Loss: 1.0136
Epoch 16 | Batch 1200/1553 | Loss: 0.9876
Epoch 16 | Batch 1300/1553 | Loss: 0.9961
Epoch 16 | Batch 1400/1553 | Loss: 1.0750
Epoch 16 | Batch 1500/1553 | Loss: 1.1054
Epoch 16 | Time: 35.2s | Train Loss: 0.9834 | Val Loss: 4.3341
Epoch 17 | Batch 0/1553 | Loss: 0.8332
Epoch 17 | Batch 100/1553 | Loss: 0.8225
Epoch 17 | Batch 200/1553 | Loss: 0.9012
Epoch 17 | Batch 300/1553 | Loss: 0.8349
Epoch 17 | Batch 400/1553 | Loss: 0.9148
Epoch 17 | Batch 500/1553 | Loss: 1.0133
Epoch 17 | Batch 600/1553 | Loss: 0.8842
Epoch 17 | Batch 700/1553 | Loss: 0.8618
Epoch 17 | Batch 800/1553 | Loss: 0.9599
Epoch 17 | Batch 900/1553 | Loss: 1.0779
Epoch 17 | Batch 1000/1553 | Loss: 0.9471
Epoch 17 | Batch 1100/1553 | Loss: 0.9846
Epoch 17 | Batch 1200/1553 | Loss: 1.0008
Epoch 17 | Batch 1300/1553 | Loss: 0.9757
Epoch 17 | Batch 1400/1553 | Loss: 0.9110
Epoch 17 | Batch 1500/1553 | Loss: 0.9588
Epoch 17 | Time: 35.1s | Train Loss: 0.9296 | Val Loss: 4.4201
Epoch 18 | Batch 0/1553 | Loss: 0.7874
Epoch 18 | Batch 100/1553 | Loss: 0.8700
Epoch 18 | Batch 200/1553 | Loss: 0.8783
Epoch 18 | Batch 300/1553 | Loss: 0.9020
Epoch 18 | Batch 400/1553 | Loss: 0.7788
Epoch 18 | Batch 500/1553 | Loss: 0.8715
Epoch 18 | Batch 600/1553 | Loss: 0.8704
Epoch 18 | Batch 700/1553 | Loss: 0.8393
Epoch 18 | Batch 800/1553 | Loss: 0.8946
Epoch 18 | Batch 900/1553 | Loss: 0.8289
Epoch 18 | Batch 1000/1553 | Loss: 0.9562
Epoch 18 | Batch 1100/1553 | Loss: 0.8541
Epoch 18 | Batch 1200/1553 | Loss: 0.9442
Epoch 18 | Batch 1300/1553 | Loss: 0.9529
Epoch 18 | Batch 1400/1553 | Loss: 0.9545
Epoch 18 | Batch 1500/1553 | Loss: 0.8843
Epoch 18 | Time: 35.5s | Train Loss: 0.8780 | Val Loss: 4.4961
Epoch 19 | Batch 0/1553 | Loss: 0.7512
Epoch 19 | Batch 100/1553 | Loss: 0.7385
Epoch 19 | Batch 200/1553 | Loss: 0.8006
Epoch 19 | Batch 300/1553 | Loss: 0.7339
Epoch 19 | Batch 400/1553 | Loss: 0.7616
Epoch 19 | Batch 500/1553 | Loss: 0.8377
Epoch 19 | Batch 600/1553 | Loss: 0.8026
Epoch 19 | Batch 700/1553 | Loss: 0.7859
Epoch 19 | Batch 800/1553 | Loss: 0.8195
Epoch 19 | Batch 900/1553 | Loss: 0.9063
Epoch 19 | Batch 1000/1553 | Loss: 0.8521
Epoch 19 | Batch 1100/1553 | Loss: 0.8346
Epoch 19 | Batch 1200/1553 | Loss: 0.8904
Epoch 19 | Batch 1300/1553 | Loss: 0.8669
Epoch 19 | Batch 1400/1553 | Loss: 0.8745
Epoch 19 | Batch 1500/1553 | Loss: 0.8762
Epoch 19 | Time: 35.6s | Train Loss: 0.8322 | Val Loss: 4.5518

Total training time: 00:12:17 (737.7s)
